{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Churn H2O v10 upsamled RF grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start cluster and import aux functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "  Java Version: openjdk version \"1.8.0_121\"; OpenJDK Runtime Environment (Zulu 8.20.0.5-macosx) (build 1.8.0_121-b15); OpenJDK 64-Bit Server VM (Zulu 8.20.0.5-macosx) (build 25.121-b15, mixed mode)\n",
      "  Starting server from /Users/donny.ho/anaconda3/envs/churn_model_27/lib/python2.7/site-packages/h2o/backend/bin/h2o.jar\n",
      "  Ice root: /var/folders/jh/c7r9rq7571jgzybkpcdg7vcr0000gp/T/tmpWqT3wg\n",
      "  JVM stdout: /var/folders/jh/c7r9rq7571jgzybkpcdg7vcr0000gp/T/tmpWqT3wg/h2o_donny_ho_started_from_python.out\n",
      "  JVM stderr: /var/folders/jh/c7r9rq7571jgzybkpcdg7vcr0000gp/T/tmpWqT3wg/h2o_donny_ho_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n",
       "<td>03 secs</td></tr>\n",
       "<tr><td>H2O cluster version:</td>\n",
       "<td>3.16.0.2</td></tr>\n",
       "<tr><td>H2O cluster version age:</td>\n",
       "<td>1 month and 21 days </td></tr>\n",
       "<tr><td>H2O cluster name:</td>\n",
       "<td>H2O_from_python_donny_ho_8i7uwb</td></tr>\n",
       "<tr><td>H2O cluster total nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster free memory:</td>\n",
       "<td>14.38 Gb</td></tr>\n",
       "<tr><td>H2O cluster total cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O cluster allowed cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O cluster status:</td>\n",
       "<td>accepting new members, healthy</td></tr>\n",
       "<tr><td>H2O connection url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O connection proxy:</td>\n",
       "<td>None</td></tr>\n",
       "<tr><td>H2O internal security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O API Extensions:</td>\n",
       "<td>XGBoost, Algos, AutoML, Core V3, Core V4</td></tr>\n",
       "<tr><td>Python version:</td>\n",
       "<td>2.7.14 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ----------------------------------------\n",
       "H2O cluster uptime:         03 secs\n",
       "H2O cluster version:        3.16.0.2\n",
       "H2O cluster version age:    1 month and 21 days\n",
       "H2O cluster name:           H2O_from_python_donny_ho_8i7uwb\n",
       "H2O cluster total nodes:    1\n",
       "H2O cluster free memory:    14.38 Gb\n",
       "H2O cluster total cores:    8\n",
       "H2O cluster allowed cores:  8\n",
       "H2O cluster status:         accepting new members, healthy\n",
       "H2O connection url:         http://127.0.0.1:54321\n",
       "H2O connection proxy:\n",
       "H2O internal security:      False\n",
       "H2O API Extensions:         XGBoost, Algos, AutoML, Core V3, Core V4\n",
       "Python version:             2.7.14 final\n",
       "--------------------------  ----------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import h2o\n",
    "import aux_functions_v2 as af\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandasql import sqldf, load_meat, load_births\n",
    "pysqldf = lambda q: sqldf(q, globals())\n",
    "#https://github.com/yhat/pandasql\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "h2o.no_progress()\n",
    "h2o.init(min_mem_size_GB=15)\n",
    "path = '/Users/donny.ho/AnacondaProjects/churn_model_poc/saved_h20_models'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'Connected: postgres@postgres'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 rows affected.\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "%load_ext sql\n",
    "%sql postgresql://@localhost/postgres\n",
    "\n",
    "f = open(\"churn_query.sql\")\n",
    "sql_statement=f.read()\n",
    "data = %sql $sql_statement\n",
    "data = data.DataFrame()\n",
    "data = af.upsample(data_frame=h2o.H2OFrame(data), minority_to_majority_ratio=1).as_data_frame()\n",
    "data['rid'] = data.index\n",
    "data['fold']  = np.random.randint(1, 11, data.shape[0])\n",
    "\n",
    "#columns_to_convert=['rf_predict','gbm_predict','glm_predict','kmeans_predict','hascrcard','isactivemember','geography','gender','exited']\n",
    "columns_to_convert=['rf_predict','gbm_predict','glm_predict','kmeans_predict','hascrcard','isactivemember','geography','gender','exited']\n",
    "training_columns = ['age','tenure','balance','numofproducts','estimatedsalary','ratio','hascrcard','isactivemember','geography','gender']\n",
    "response_column = 'exited'\n",
    "data = h2o.H2OFrame(data)\n",
    "\n",
    "train, test, valid = data.split_frame([0.70,0.15], seed=1234)\n",
    "train       = train.as_data_frame()\n",
    "test        = test.as_data_frame()\n",
    "train_meta  = train.copy(deep=True)\n",
    "test_meta   = test.copy(deep=True)\n",
    "\n",
    "train      = af.column_to_factors(train,columns_to_convert)\n",
    "test       = af.column_to_factors(test,columns_to_convert)\n",
    "train_meta = af.column_to_factors(train_meta,columns_to_convert)\n",
    "test_meta  = af.column_to_factors(test_meta,columns_to_convert)\n",
    "print('Done')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forrest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training model: ', 1)\n",
      "('Training model: ', 2)\n",
      "('Training model: ', 3)\n",
      "('Training model: ', 4)\n",
      "('Training model: ', 5)\n",
      "('Training model: ', 6)\n",
      "('Training model: ', 7)\n",
      "('Training model: ', 8)\n",
      "('Training model: ', 9)\n",
      "('Training model: ', 10)\n",
      "('Training model: ', 11)\n"
     ]
    }
   ],
   "source": [
    "from h2o.estimators import H2ORandomForestEstimator\n",
    "\n",
    "model_id=\"rf\"\n",
    "\n",
    "rf = H2ORandomForestEstimator(\n",
    "    model_id                          = model_id,\n",
    "    nfolds                            = 10,\n",
    "    ntrees                            = 700,\n",
    "    max_depth                         = 15,\n",
    "    stopping_rounds                   = 3,\n",
    "    stopping_tolerance                = 0.005,\n",
    "    #nbins_cats                        = 128,\n",
    "    #nbins                             = 128,\n",
    "    score_each_iteration              = True,\n",
    "    fold_assignment                   = \"Modulo\",\n",
    "    keep_cross_validation_predictions = True,\n",
    "    stopping_metric                   = 'AUC',\n",
    "    seed                              = 3000000,\n",
    "    col_sample_rate_change_per_level  = 0.85\n",
    ")\n",
    "\n",
    "for k in range(1,12):\n",
    "    print('Training model: ',k)\n",
    "    if k<11:\n",
    "        test_fold  = train[train['fold'] == k]\n",
    "        train_fold = train[train['fold'] != k]\n",
    "        table_to_insert = train_meta.as_data_frame()\n",
    "    if k==11:\n",
    "        test_fold  = test\n",
    "        train_fold = train\n",
    "        table_to_insert = test_meta.as_data_frame()\n",
    "\n",
    "    rf.train(x=training_columns, \n",
    "                      y=response_column, \n",
    "                      training_frame=train_fold,\n",
    "                      validation_frame=valid\n",
    "                     )\n",
    "    #intermediate_frame = pd.concat([test_fold.as_data_frame(), rf.predict(test_fold).as_data_frame()], axis=1)[['fold','rid','predict']]\n",
    "    intermediate_frame = test_fold[['fold','rid','exited']].cbind(rf.predict(test_fold)[['p1','predict']]).as_data_frame()\n",
    "\n",
    "    sql_query = '''\n",
    "    SELECT\n",
    "        A.fold,\n",
    "        A.rid,\n",
    "        COALESCE(B.predict, A.rf_predict) as rf_predict,\n",
    "        COALESCE(B.p1, A.rf_predict_prob) as rf_predict_prob,\n",
    "        A.gbm_predict,\n",
    "        A.gbm_predict_prob,\n",
    "        A.glm_predict,\n",
    "        A.glm_predict_prob,\n",
    "        A.xgboost_predict,\n",
    "        A.xgboost_predict_prob,\n",
    "        A.kmeans_predict,\n",
    "        A.age,\n",
    "        A.tenure,\n",
    "        A.balance,\n",
    "        A.numofproducts,\n",
    "        A.estimatedsalary,\n",
    "        A.ratio,\n",
    "        A.hascrcard,\n",
    "        A.isactivemember,\n",
    "        A.geography,\n",
    "        A.gender,\n",
    "        A.exited\n",
    "    FROM table_to_insert AS A \n",
    "    LEFT JOIN intermediate_frame AS B ON A.fold = B.fold AND A.rid = B.rid \n",
    "    '''\n",
    "    #pysqldf(sql_query)\n",
    "    if k<11:\n",
    "        train_meta = af.column_to_factors(pysqldf(sql_query),columns_to_convert)\n",
    "        \n",
    "    if k==11:\n",
    "        test_meta = af.column_to_factors(pysqldf(sql_query),columns_to_convert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train_meta\n",
    "#test_fold[['fold','rid','exited']].cbind(glm.predict(test_fold)[['p1','predict']]).as_data_frame()\n",
    "#rf.predict(test_fold)\n",
    "#test_fold[['fold','rid','exited']].cbind(rf.predict(test_fold)['p1']).as_data_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training model: ', 1)\n",
      "('Training model: ', 2)\n",
      "('Training model: ', 3)\n",
      "('Training model: ', 4)\n",
      "('Training model: ', 5)\n",
      "('Training model: ', 6)\n",
      "('Training model: ', 7)\n",
      "('Training model: ', 8)\n",
      "('Training model: ', 9)\n",
      "('Training model: ', 10)\n",
      "('Training model: ', 11)\n"
     ]
    }
   ],
   "source": [
    "from h2o.estimators import H2OGradientBoostingEstimator\n",
    "\n",
    "model_id=\"gbm\"\n",
    "\n",
    "gbm = H2OGradientBoostingEstimator(\n",
    "    model_id                          = model_id,\n",
    "    nfolds                            = 10,\n",
    "    ntrees                            = 700,\n",
    "    max_depth                         = 15,\n",
    "    stopping_rounds                   = 3,\n",
    "    stopping_tolerance                = 0.005,\n",
    "    #nbins_cats                        = 128,\n",
    "    #nbins                             = 128,\n",
    "    score_each_iteration              = True,\n",
    "    fold_assignment                   = \"Modulo\",\n",
    "    keep_cross_validation_predictions = True,\n",
    "    distribution                      ='AUTO',\n",
    "    stopping_metric                   = 'AUC',\n",
    "    seed                              = 3000000,\n",
    "    col_sample_rate_change_per_level  = 0.85\n",
    ")\n",
    "\n",
    "for k in range(1,12):\n",
    "    print('Training model: ',k)\n",
    "    if k<11:\n",
    "        test_fold  = train[train['fold'] == k]\n",
    "        train_fold = train[train['fold'] != k]\n",
    "        table_to_insert = train_meta.as_data_frame()\n",
    "    if k==11:\n",
    "        test_fold  = test\n",
    "        train_fold = train\n",
    "        table_to_insert = test_meta.as_data_frame()\n",
    "\n",
    "    gbm.train(x=training_columns, \n",
    "                      y=response_column, \n",
    "                      training_frame=train_fold,\n",
    "                      validation_frame=valid\n",
    "                     )\n",
    "    #intermediate_frame = pd.concat([test_fold.as_data_frame(), gbm.predict(test_fold).as_data_frame()], axis=1)[['fold','rid','predict']]\n",
    "    intermediate_frame = test_fold[['fold','rid','exited']].cbind(gbm.predict(test_fold)[['p1','predict']]).as_data_frame()\n",
    "    sql_query = '''\n",
    "    --SELECT COUNT(*) FROM intermediate_frame\n",
    "    SELECT\n",
    "        A.fold,\n",
    "        A.rid,\n",
    "        A.rf_predict,\n",
    "        A.rf_predict_prob,\n",
    "        COALESCE(B.predict, A.gbm_predict) as gbm_predict,\n",
    "        COALESCE(B.p1, A.gbm_predict_prob) as gbm_predict_prob,\n",
    "        A.glm_predict,\n",
    "        A.glm_predict_prob,\n",
    "        A.xgboost_predict,\n",
    "        A.xgboost_predict_prob,\n",
    "        A.kmeans_predict,\n",
    "        A.age,\n",
    "        A.tenure,\n",
    "        A.balance,\n",
    "        A.numofproducts,\n",
    "        A.estimatedsalary,\n",
    "        A.ratio,\n",
    "        A.hascrcard,\n",
    "        A.isactivemember,\n",
    "        A.geography,\n",
    "        A.gender,\n",
    "        A.exited\n",
    "    FROM table_to_insert AS A \n",
    "    LEFT JOIN intermediate_frame AS B ON A.fold = B.fold AND A.rid = B.rid \n",
    "    '''\n",
    "    #pysqldf(sql_query)\n",
    "    if k<11:\n",
    "        train_meta = af.column_to_factors(pysqldf(sql_query),columns_to_convert)\n",
    "        \n",
    "    if k==11:\n",
    "        test_meta = af.column_to_factors(pysqldf(sql_query),columns_to_convert)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training model: ', 1)\n",
      "('Training model: ', 2)\n",
      "('Training model: ', 3)\n",
      "('Training model: ', 4)\n",
      "('Training model: ', 5)\n",
      "('Training model: ', 6)\n",
      "('Training model: ', 7)\n",
      "('Training model: ', 8)\n",
      "('Training model: ', 9)\n",
      "('Training model: ', 10)\n",
      "('Training model: ', 11)\n"
     ]
    }
   ],
   "source": [
    "from h2o.estimators.glm import H2OGeneralizedLinearEstimator\n",
    "\n",
    "model_id=\"glm\"\n",
    "\n",
    "glm = H2OGeneralizedLinearEstimator(\n",
    "    model_id                          = model_id,\n",
    "    family                            ='binomial', \n",
    "    lambda_search                     = True,\n",
    "    score_each_iteration              = True,\n",
    "    nfolds                            = 10,\n",
    "    fold_assignment                   = \"Modulo\",\n",
    "    keep_cross_validation_predictions = True, \n",
    "    seed                              = 3000000\n",
    ")\n",
    "\n",
    "for k in range(1,12):\n",
    "    print('Training model: ',k)\n",
    "    if k<11:\n",
    "        test_fold  = train[train['fold'] == k]\n",
    "        train_fold = train[train['fold'] != k]\n",
    "        table_to_insert = train_meta.as_data_frame()\n",
    "    if k==11:\n",
    "        test_fold  = test\n",
    "        train_fold = train\n",
    "        table_to_insert = test_meta.as_data_frame()\n",
    "\n",
    "    glm.train(x=training_columns, \n",
    "                      y=response_column, \n",
    "                      training_frame=train_fold,\n",
    "                      validation_frame=valid\n",
    "                     )\n",
    "    intermediate_frame = test_fold[['fold','rid','exited']].cbind(glm.predict(test_fold)[['p1','predict']]).as_data_frame()\n",
    "\n",
    "    sql_query = '''\n",
    "    --SELECT COUNT(*) FROM intermediate_frame\n",
    "    SELECT\n",
    "        A.fold,\n",
    "        A.rid,\n",
    "        A.rf_predict,\n",
    "        A.rf_predict_prob,\n",
    "        A.gbm_predict,\n",
    "        A.gbm_predict_prob,\n",
    "        COALESCE(B.predict, A.glm_predict) as glm_predict,\n",
    "        COALESCE(B.p1, A.glm_predict_prob) as glm_predict_prob,\n",
    "        A.xgboost_predict,\n",
    "        A.xgboost_predict_prob,\n",
    "        A.kmeans_predict,\n",
    "        A.age,\n",
    "        A.tenure,\n",
    "        A.balance,\n",
    "        A.numofproducts,\n",
    "        A.estimatedsalary,\n",
    "        A.ratio,\n",
    "        A.hascrcard,\n",
    "        A.isactivemember,\n",
    "        A.geography,\n",
    "        A.gender,\n",
    "        A.exited\n",
    "    FROM table_to_insert AS A \n",
    "    LEFT JOIN intermediate_frame AS B ON A.fold = B.fold AND A.rid = B.rid \n",
    "    '''\n",
    "    #pysqldf(sql_query)\n",
    "    if k<11:\n",
    "        train_meta = af.column_to_factors(pysqldf(sql_query),columns_to_convert)\n",
    "        \n",
    "    if k==11:\n",
    "        test_meta = af.column_to_factors(pysqldf(sql_query),columns_to_convert)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training model: ', 1)\n",
      "('Training model: ', 2)\n",
      "('Training model: ', 3)\n"
     ]
    }
   ],
   "source": [
    "from h2o.estimators.xgboost import H2OXGBoostEstimator\n",
    "\n",
    "model_id=\"xgboost\"\n",
    "\n",
    "param = {\n",
    "    \"model_id\"                          : model_id,\n",
    "    \"ntrees\"                            : 1000,\n",
    "    \"max_depth\"                         : 14,\n",
    "    \"learn_rate\"                        : 0.02,\n",
    "    \"sample_rate\"                       : 0.85,\n",
    "    #\"col_sample_rate_per_tree\"          : 0.9,\n",
    "    #\"min_rows\"                          : 5,\n",
    "    \"nfolds\"                            : 10,\n",
    "    \"fold_assignment\"                   : \"Modulo\",\n",
    "    \"seed\"                              : 3000000,\n",
    "    \"score_tree_interval\"               : 100,\n",
    "    \"score_each_iteration\"              : True,\n",
    "    \"fold_assignment\"                   : \"Modulo\",\n",
    "    \"keep_cross_validation_predictions\" : True\n",
    "}\n",
    "\n",
    "xgboost = H2OXGBoostEstimator(**param)\n",
    "\n",
    "for k in range(1,12):\n",
    "    print('Training model: ',k)\n",
    "    if k<11:\n",
    "        test_fold  = train[train['fold'] == k]\n",
    "        train_fold = train[train['fold'] != k]\n",
    "        table_to_insert = train_meta.as_data_frame()\n",
    "    if k==11:\n",
    "        test_fold  = test\n",
    "        train_fold = train\n",
    "        table_to_insert = test_meta.as_data_frame()\n",
    "\n",
    "    xgboost.train(x=training_columns, \n",
    "                  y=response_column,\n",
    "                  training_frame=train_fold\n",
    "                  #validation_frame=valid\n",
    "                     )\n",
    "    intermediate_frame = test_fold[['fold','rid','exited']].cbind(xgboost.predict(test_fold)[['p1','predict']]).as_data_frame()\n",
    "\n",
    "    sql_query = '''\n",
    "    SELECT\n",
    "        A.fold,\n",
    "        A.rid,\n",
    "        A.rf_predict,\n",
    "        A.rf_predict_prob,\n",
    "        A.gbm_predict,\n",
    "        A.gbm_predict_prob,\n",
    "        A.glm_predict,\n",
    "        A.glm_predict_prob,\n",
    "        COALESCE(B.predict, A.xgboost_predict) AS xgboost_predict,\n",
    "        COALESCE(B.p1, A.xgboost_predict_prob) AS xgboost_predict_prob,\n",
    "        A.kmeans_predict,\n",
    "        A.age,\n",
    "        A.tenure,\n",
    "        A.balance,\n",
    "        A.numofproducts,\n",
    "        A.estimatedsalary,\n",
    "        A.ratio,\n",
    "        A.hascrcard,\n",
    "        A.isactivemember,\n",
    "        A.geography,\n",
    "        A.gender,\n",
    "        A.exited\n",
    "    FROM table_to_insert AS A \n",
    "    LEFT JOIN intermediate_frame AS B ON A.fold = B.fold AND A.rid = B.rid \n",
    "    '''\n",
    "    #pysqldf(sql_query)\n",
    "    if k<11:\n",
    "        train_meta = af.column_to_factors(pysqldf(sql_query),columns_to_convert)\n",
    "        \n",
    "    if k==11:\n",
    "        test_meta = af.column_to_factors(pysqldf(sql_query),columns_to_convert)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-MEANS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from h2o.estimators import H2OKMeansEstimator\n",
    "\n",
    "model_id=\"kmeans\"\n",
    "training_columns = ['age','tenure','balance','numofproducts','estimatedsalary','ratio','hascrcard','isactivemember','geography','gender']\n",
    "response_column = 'exited'\n",
    "\n",
    "kmeans = H2OKMeansEstimator(\n",
    "    model_id                          = model_id,\n",
    "    k                                 = 10,\n",
    "    #score_each_iteration              = True,\n",
    "    #fold_assignment                   = \"Modulo\",\n",
    "    #keep_cross_validation_predictions = True,\n",
    "    #stopping_metric                   = 'MSE',\n",
    "    seed                              = 3000000\n",
    ")\n",
    "\n",
    "for k in range(1,12):\n",
    "    print('Training model: ',k)\n",
    "    if k<11:\n",
    "        test_fold  = train[train['fold'] == k]\n",
    "        train_fold = train[train['fold'] != k]\n",
    "        table_to_insert = train_meta.as_data_frame()\n",
    "    if k==11:\n",
    "        test_fold  = test\n",
    "        train_fold = train\n",
    "        table_to_insert = test_meta.as_data_frame()\n",
    "\n",
    "    kmeans.train(x=training_columns, \n",
    "                      training_frame=train_fold,\n",
    "                      #validation_frame=valid\n",
    "                     )\n",
    "    #intermediate_frame = pd.concat([test_fold.as_data_frame(), kmeans.predict(test_fold).as_data_frame()], axis=1)[['fold','rid','predict']]\n",
    "    intermediate_frame = test_fold[['fold','rid','exited']].cbind(kmeans.predict(test_fold)['predict']).as_data_frame()\n",
    "\n",
    "    sql_query = '''\n",
    "    SELECT\n",
    "        A.fold,\n",
    "        A.rid,\n",
    "        A.rf_predict,\n",
    "        A.rf_predict_prob,\n",
    "        A.gbm_predict,\n",
    "        A.gbm_predict_prob,\n",
    "        A.glm_predict,\n",
    "        A.glm_predict_prob,\n",
    "        A.xgboost_predict,\n",
    "        A.xgboost_predict_prob,\n",
    "        COALESCE(B.predict, A.kmeans_predict) AS kmeans_predict,\n",
    "        A.age,\n",
    "        A.tenure,\n",
    "        A.balance,\n",
    "        A.numofproducts,\n",
    "        A.estimatedsalary,\n",
    "        A.ratio,\n",
    "        A.hascrcard,\n",
    "        A.isactivemember,\n",
    "        A.geography,\n",
    "        A.gender,\n",
    "        A.exited\n",
    "    FROM table_to_insert AS A \n",
    "    LEFT JOIN intermediate_frame AS B ON A.fold = B.fold AND A.rid = B.rid \n",
    "    '''\n",
    "    #pysqldf(sql_query)\n",
    "    if k<11:\n",
    "        train_meta = af.column_to_factors(pysqldf(sql_query),columns_to_convert)\n",
    "        \n",
    "    if k==11:\n",
    "        test_meta = af.column_to_factors(pysqldf(sql_query),columns_to_convert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from h2o.estimators.xgboost import H2OXGBoostEstimator\n",
    "param = {\n",
    "      \"ntrees\" : 1000\n",
    "    , \"max_depth\" : 14\n",
    "    , \"learn_rate\" : 0.02\n",
    "    , \"sample_rate\" : 0.85\n",
    "    #, \"col_sample_rate_per_tree\" : 0.9\n",
    "    #, \"min_rows\" : 5\n",
    "    , \"seed\": 3000000\n",
    "    , \"score_tree_interval\": 100\n",
    "}\n",
    "print('Start')\n",
    "\n",
    "#training_columns =  ['rf_predict','gbm_predict','glm_predict','kmeans_predict','age','tenure','balance','numofproducts','estimatedsalary','ratio','hascrcard','isactivemember','geography','gender']\n",
    "#training_columns = ['rf_predict','kmeans_predict','age','tenure','balance','estimatedsalary','ratio','hascrcard','isactivemember','geography','gender']\n",
    "\n",
    "#training_columns = ['age','tenure','balance','numofproducts','estimatedsalary','ratio','hascrcard','isactivemember','geography','gender'] # 0.982254\n",
    "#training_columns = ['rf_predict','age','tenure','balance','numofproducts','estimatedsalary','ratio','hascrcard','isactivemember','geography','gender'] # 0.81296\n",
    "#training_columns = ['rf_predict','age','tenure','balance','estimatedsalary','ratio','hascrcard','isactivemember','geography','gender'] # 0.7859\n",
    "#training_columns = ['kmeans_predict','age','tenure','balance','numofproducts','estimatedsalary','ratio','hascrcard','isactivemember','geography','gender'] # 0.977489\n",
    "#training_columns = ['glm_predict','kmeans_predict','age','tenure','balance','numofproducts','estimatedsalary','ratio','hascrcard','isactivemember','geography','gender'] # 0.962398\n",
    "training_columns = ['glm_predict','kmeans_predict','age','tenure','balance','numofproducts','estimatedsalary','ratio','hascrcard','isactivemember','geography','gender'] # 0.\n",
    "\n",
    "response_column  = 'exited'\n",
    "xgboost = H2OXGBoostEstimator(**param)\n",
    "xgboost.train(x=training_columns, \n",
    "   y=response_column, \n",
    "   training_frame=af.column_to_factors(train_meta,columns_to_convert)\n",
    "   #validation_frame=valid\n",
    "             )\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# H2O STACKING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from h2o.estimators.stackedensemble import H2OStackedEnsembleEstimator\n",
    "\n",
    "all_model_ids=[rf.model_id,gbm.model_id,glm.model_id,xgboost.model_id]\n",
    "\n",
    "ensemble = H2OStackedEnsembleEstimator(base_models = all_model_ids)\n",
    "\n",
    "ensemble.train(x=training_columns, y=response_column, training_frame=train, validation_frame=valid)\n",
    "\n",
    "#h2o.save_model(model=ensemble, path=path, force=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import metric_validation as mv\n",
    "#mv.metrics(ensemble,test,'p1')\n",
    "mv1.roc_plot(xgboost,test_meta,'p1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GBM STACKED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from h2o.estimators import H2OGradientBoostingEstimator\n",
    "\n",
    "model_id=\"gbm_stacked\"\n",
    "\n",
    "#training_columns = ['rf_predict','rf_predict_prob','gbm_predict','gbm_predict_prob','glm_predict','glm_predict_prob','xgboost_predict','xgboost_predict_prob','kmeans_predict','age','tenure','balance','numofproducts','estimatedsalary','ratio','hascrcard','isactivemember','geography','gender']\n",
    "# 0.98097\n",
    "#training_columns = ['rf_predict','rf_predict_prob','gbm_predict','gbm_predict_prob','glm_predict_prob','xgboost_predict','xgboost_predict_prob','kmeans_predict','age','tenure','balance','numofproducts','estimatedsalary','ratio','hascrcard','isactivemember','geography','gender'] # 0.\n",
    "# 0.97908\n",
    "#training_columns = ['rf_predict','rf_predict_prob','gbm_predict','gbm_predict_prob','glm_predict_prob','xgboost_predict_prob','kmeans_predict','age','tenure','balance','numofproducts','estimatedsalary','ratio','hascrcard','isactivemember','geography','gender'] # 0.\n",
    "# 0.981793\n",
    "#training_columns = ['rf_predict_prob','gbm_predict','gbm_predict_prob','glm_predict_prob','xgboost_predict_prob','kmeans_predict','age','tenure','balance','numofproducts','estimatedsalary','ratio','hascrcard','isactivemember','geography','gender'] # 0.\n",
    "# 0.976479\n",
    "#training_columns = ['rf_predict_prob','gbm_predict','gbm_predict_prob','glm_predict_prob','xgboost_predict_prob','kmeans_predict','age','tenure','balance','estimatedsalary','ratio','hascrcard','isactivemember','geography','gender'] # 0.\n",
    "# 0.983668\n",
    "#training_columns = ['rf_predict_prob','gbm_predict_prob','glm_predict_prob','xgboost_predict_prob','kmeans_predict','age','tenure','balance','estimatedsalary','ratio','hascrcard','isactivemember','geography','gender'] # 0.\n",
    "# 0.975641\n",
    "#training_columns = ['rf_predict_prob','gbm_predict_prob','glm_predict_prob','xgboost_predict_prob','kmeans_predict','age','tenure','balance','estimatedsalary','ratio','hascrcard','geography','gender'] # 0.\n",
    "# 0.979778\n",
    "\n",
    "gbm_stacked = H2OGradientBoostingEstimator(\n",
    "    model_id                          = model_id,\n",
    "    nfolds                            = 10,\n",
    "    ntrees                            = 700,\n",
    "    max_depth                         = 15,\n",
    "    stopping_rounds                   = 3,\n",
    "    stopping_tolerance                = 0.005,\n",
    "    #nbins_cats                        = 128,\n",
    "    #nbins                             = 128,\n",
    "    score_each_iteration              = True,\n",
    "    fold_assignment                   = \"Modulo\",\n",
    "    keep_cross_validation_predictions = True,\n",
    "    distribution                      ='AUTO',\n",
    "    stopping_metric                   = 'AUC',\n",
    "    seed                              = 3000000,\n",
    "    col_sample_rate_change_per_level  = 0.85\n",
    ")\n",
    "\n",
    "\n",
    "gbm_stacked.train(x=training_columns, \n",
    "                  y=response_column, \n",
    "                  training_frame=train_meta\n",
    "                  #validation_frame=valid\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import metric_validation as mv1\n",
    "mv1.roc_plot(gbm_stacked,test_meta,'p1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mv.metrics(gbm_stacked,test_meta) \n",
    "mv.metrics(rf,test_meta) \n",
    "mv.metrics(gbm,test_meta) \n",
    "mv.metrics(glm,test_meta) \n",
    "mv.metrics(xgboost,test_meta) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_training_columns():\n",
    "    train_col = ['rf_predict','rf_predict_prob','gbm_predict','gbm_predict_prob','glm_predict','glm_predict_prob','xgboost_predict','xgboost_predict_prob','kmeans_predict','age','tenure','balance','numofproducts','estimatedsalary','ratio','hascrcard','isactivemember','geography','gender']\n",
    "    pwrset = list(powerset(train_col))\n",
    "    i=0\n",
    "    traning_col_list = []\n",
    "    gen = (x for x in iter(pwrset) if (len(list(x))>=8) )\n",
    "    for x in range(1,10):\n",
    "        col_info = {}\n",
    "        col_info['training_columns'] = random.choice(pwrset)\n",
    "        col_info['index'] = i\n",
    "        traning_col_list.append(col_info)\n",
    "        i=i+1\n",
    "    return traning_col_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = random_training_columns()\n",
    "#list(r[0]['training_columns'])\n",
    "i=0\n",
    "for col in r:\n",
    "    #print(col)\n",
    "    #print('training set: ', col['index'])\n",
    "    gbm_stacked.train(x=list(col['training_columns']), \n",
    "                  y=response_column, \n",
    "                  training_frame=train_meta\n",
    "                     )\n",
    "    \n",
    "    r[i]['model'] = gbm_stacked\n",
    "    r[i]['metrics'] = mv.metrics(gbm_stacked,train_meta)\n",
    "    i=i+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r[0]['metrics']\n",
    "r[0]['training_columns']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import metric_validation as mv\n",
    "mv.roc_plot(xgboost,test_meta,'p1')\n",
    "traning_col_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "classifier = xgboost\n",
    "test_frame = test_meta\n",
    "\n",
    "column='p1'\n",
    "\n",
    "actual = test_frame.as_data_frame()\n",
    "print(classifier.predict(test_frame).columns)\n",
    "predictions = classifier.predict(test_frame).as_data_frame()[column].tolist()\n",
    "\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(actual.exited.astype('float'), predictions)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(false_positive_rate, true_positive_rate, 'b',\n",
    "label='AUC = %0.6f'% roc_auc)\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0,1],[0,1],'r--')\n",
    "plt.plot([0,1],[1,1],'r--')\n",
    "plt.xlim([-0.1,1.2])\n",
    "plt.ylim([-0.1,1.2])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metrics(xgboost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import metric_validation as mv\n",
    "# with original training column because the one I had in XGBOOST was accidentally wrong auc = 0.982254\n",
    "# without pre_trained_models  auc = 0.970926\n",
    "# without hascard auc = 0.965060\n",
    "# with kmeans auc = 0.966456\n",
    "# with kmeans but without hascard auc = 0.965060\n",
    "\n",
    "mv.roc_plot(xgboost,test_frame=test_meta,column='p1')\n",
    "mv.roc_plot(rf,test_frame=test_meta,column='p1')\n",
    "mv.roc_plot(gbm,test_frame=test_meta,column='p1')\n",
    "mv.roc_plot(glm,test_frame=test_meta,column='p1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def metrics(predictor,test_frame):\n",
    "    #consolidate_frame = test_meta['exited'].cbind(xgboost.predict(test_meta)['predict'])\n",
    "    consolidate_frame = test_frame['exited'].cbind(predictor.predict(test_frame)['predict'])\n",
    "\n",
    "    accuracy = float(len(consolidate_frame[consolidate_frame['exited']==consolidate_frame['predict']]))/len(consolidate_frame)\n",
    "    accuracy\n",
    "\n",
    "\n",
    "\n",
    "    true_positives = consolidate_frame[(consolidate_frame['exited']==consolidate_frame['predict'])\n",
    "                                      &(consolidate_frame['exited'].asnumeric() ==1)]\n",
    "\n",
    "    false_positives = consolidate_frame[(consolidate_frame['exited']!=consolidate_frame['predict'])\n",
    "                                      &(consolidate_frame['exited'].asnumeric() ==1)]\n",
    "\n",
    "    true_positive_rate = float(len(true_positives))/(len(false_positives)+len(true_positives))\n",
    "    true_positive_rate\n",
    "\n",
    "\n",
    "\n",
    "    true_negatives = consolidate_frame[(consolidate_frame['exited']==consolidate_frame['predict'])\n",
    "                                      &(consolidate_frame['exited'].asnumeric() ==0)]\n",
    "\n",
    "    false_negatives = consolidate_frame[(consolidate_frame['exited']!=consolidate_frame['predict'])\n",
    "                                      &(consolidate_frame['exited'].asnumeric() ==0)]\n",
    "\n",
    "    true_negative_rate = float(len(true_negatives))/(len(false_negatives)+len(true_negatives))\n",
    "    true_negative_rate\n",
    "    return [accuracy, true_positive_rate, true_negative_rate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metrics(xgboost, test_frame = test_meta)\n",
    "metrics(rf, test_frame = test_meta)\n",
    "metrics(gbm, test_frame = test_meta)\n",
    "metrics(glm, test_frame = test_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload mv\n",
    "%autoreload metric_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def powerset(L):\n",
    "  pset = set()\n",
    "  for n in xrange(len(L) + 1):\n",
    "    for sset in itertools.combinations(L, n):\n",
    "      pset.add(sset)\n",
    "  return pset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
